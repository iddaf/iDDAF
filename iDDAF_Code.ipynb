{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import openpyxl\n",
    "import os\n",
    "from functions.functions_for_dataload import *\n",
    "from openpyxl import load_workbook\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "import random \n",
    "import time \n",
    "import sys \n",
    "\n",
    "%matplotlib inline\n",
    "sys_Data = []\n",
    "from functions.fnc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "sns.set_style('white')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time\n",
    "import matplotlib.ticker as tkr\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "%matplotlib inline\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "import random \n",
    "from keras.models import load_model\n",
    "from ortools.linear_solver import pywraplp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Time-Series Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfBuses = 14\n",
    "numOfLines = 20\n",
    "import pandas as pd\n",
    "freq = 'sec'\n",
    "if freq == 'sec':\n",
    "    senData = pd.read_csv(f\"Bus Data\\\\IEEE_{numOfBuses}_Bus_Time_Series_30_Sec.csv\", index_col = 0)\n",
    "    senData.index = pd.to_datetime(senData.index)\n",
    "    #senData = senData.iloc[0:25000]\n",
    "elif freq == 'min':\n",
    "    senData = pd.read_csv(f\"Bus Data\\\\IEEE_{numOfBuses}_Bus_Time_Series_Hourly.csv\", index_col = 0) \n",
    "    senData.index = pd.to_datetime(senData.index)\n",
    "    senData = senData.resample('1T').asfreq().interpolate()\n",
    "###############################\n",
    "\n",
    "sensors = numOfBuses + 2* numOfLines\n",
    "\n",
    "dataset_org = senData.values.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset_org)\n",
    "train_size = int(len(dataset) * 0.80)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "dataset.shape\n",
    "############\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, :])\n",
    "    return np.array(X), np.array(Y)\n",
    "    \n",
    "look_back = 20\n",
    "X_train, Y_train = create_dataset(train, look_back)\n",
    "X_test, Y_test = create_dataset(test, look_back)\n",
    "Y_test = scaler.inverse_transform(Y_test)\n",
    "Y_train = scaler.inverse_transform(Y_train)\n",
    "\n",
    "print(X_test.shape, Y_test.shape)\n",
    "################\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[2], X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[2], X_test.shape[1]))\n",
    "############\n",
    "model = load_model(f'LSTM Model\\\\IEEE_{numOfBuses}_LSTM.h5')\n",
    "print(\"Model Loaded!\")\n",
    "##############\n",
    "sensorData = scaler.inverse_transform(Y_test)\n",
    "\n",
    "timeIndx = 0\n",
    "# LSTM Prediction\n",
    "def predictLSTM (indexx):\n",
    "    #numOfZ = 54\n",
    "    Zpre = pd.DataFrame([])\n",
    "    Zpre['ID'] = np.arange(1, numOfZ + 1 )\n",
    "    Zpre['MS'] = scaler.inverse_transform(model.predict(X_test[indexx:indexx+1]))[0]\n",
    "    Zpre['MS'].iloc[-numOfBuses:] = Zpre['MS'].iloc[-numOfBuses:]*-1\n",
    "    return Zpre\n",
    "#predictLSTM (timeIndx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repair_Algorithm(numOfBuses, numOfLines, predicted, received, fixedIDs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "listOfx = []\n",
    "\n",
    "def runMatch(numOfBuses, numOfLines, predicted, received, fixedIDs, decoyIDDs):\n",
    "    \n",
    "    dataCheck = [predicted.copy(), received.copy()]\n",
    "\n",
    "    num_sensors = predicted.shape[0]\n",
    "    num_measures = received.shape[0]\n",
    "\n",
    "    #costs\n",
    "    costs = []\n",
    "    for p in predicted['MS']:\n",
    "        costs.append(list(abs(received['MS'] - p)))\n",
    "\n",
    "\n",
    "    for l in fixedIDs:\n",
    "        try:\n",
    "            i = pd.Index(predicted['ID']).get_loc(l)\n",
    "            j = pd.Index(received['ID']).get_loc(l)\n",
    "            costs[i][j] = 0\n",
    "        except:\n",
    "            print(f\"Sensor {l} does not exit\")\n",
    "            break \n",
    "\n",
    "    th = 10\n",
    "\n",
    "    # Threshold\n",
    "    th_max = abs(predicted['MS']*th/100)\n",
    "    th_max = np.ceil(th_max)\n",
    "    th_max[th_max == 0] = 1\n",
    "\n",
    "    numOfSoln = 0\n",
    "    maxSoln = 1\n",
    "    \n",
    "    listOfind = []\n",
    "#     listOfx = []\n",
    "\n",
    "    #Stating the loop to find multiple solutions\n",
    "    while(numOfSoln < maxSoln):\n",
    "        \n",
    "        #print(\"Starting mapping...\")\n",
    "\n",
    "        # Create the mip solver with the CBC backend.\n",
    "        solver = pywraplp.Solver.CreateSolver('assignment_mip', 'CBC')\n",
    "        #####################################################################\n",
    "\n",
    "        # x[i, j] is an array of 0-1 variables, which will be 1\n",
    "        # if sensor i is assigned to a measurement j.\n",
    "        x = {}\n",
    "        for i in range(num_sensors):\n",
    "            for j in range(num_measures):\n",
    "                x[i, j] = solver.IntVar(0, 1, '')\n",
    "\n",
    "        #####################################################################\n",
    "        # Each sensor is assigned to at most 1 measurement.\n",
    "        for i in range(num_sensors):\n",
    "            solver.Add(solver.Sum([x[i, j] for j in range(num_measures)]) <= 1)\n",
    "\n",
    "        #####################################################################    \n",
    "        # Each measurement is assigned to at most 1 sensor.\n",
    "        for j in range(num_measures):\n",
    "            solver.Add(solver.Sum([x[i, j] for i in range(num_sensors)]) <= 1)\n",
    "\n",
    "        #####################################################################\n",
    "        \n",
    "        # Droping Decoy IDs\n",
    "        for d in decoyIDDs:\n",
    "            try:\n",
    "                j = pd.Index(received['ID']).get_loc(d)\n",
    "                solver.Add(solver.Sum([x[i, j] for i in range(num_sensors)]) == 0)\n",
    "            except:\n",
    "                print(f\"Sensor {d} does not exit\")\n",
    "                break        \n",
    "                \n",
    "        #####################################################################\n",
    "        \n",
    "        # Assigning the fixed IDs\n",
    "        for l in fixedIDs:\n",
    "            try:\n",
    "                i = pd.Index(predicted['ID']).get_loc(l)\n",
    "                j = pd.Index(received['ID']).get_loc(l)\n",
    "                solver.Add(x[i,j] == 1)\n",
    "            except:\n",
    "                print(f\"Sensor {l} does not exit\")\n",
    "                break        \n",
    "        \n",
    "#         for i in fixedIDs:\n",
    "#             solver.Add(x[i-1,i-1] == 1)\n",
    "\n",
    "        ######################################################################\n",
    "        # Each received values should be withing the predicted threshold \n",
    "        for i in range(num_sensors):\n",
    "            for j in range(num_measures):\n",
    "                if costs[i][j]>th_max[i]:\n",
    "                    solver.Add(x[i,j] == 0)\n",
    "\n",
    "        # solver.Add(solver.Sum([x[i, j] for i in range(num_workers) \n",
    "        #                        for j in range(num_tasks)]) == num_workers )\n",
    "        # solver.Add(solver.Sum(x) >= 4)\n",
    "\n",
    "        #######################################################################\n",
    "        # Finding the next solutions\n",
    "        if numOfSoln > 0:\n",
    "\n",
    "            for x_prev in listOfx:\n",
    "                cond = []\n",
    "                totalX = sum(sum(x_prev))\n",
    "                for i in range(num_sensors):\n",
    "                    for j in range(num_measures):\n",
    "                        cond.append(x[i,j] * x_prev[i,j])\n",
    "                solver.Add(solver.Sum(cond) <= totalX-1)                       \n",
    "        ####################################################################\n",
    "        # The following code creates the objective function for the problem.\n",
    "\n",
    "        objective_terms_loss = []\n",
    "        objective_terms_assign = []\n",
    "\n",
    "        for i in range(num_sensors):\n",
    "            for j in range(num_measures):\n",
    "                objective_terms_loss.append(costs[i][j] * x[i, j])\n",
    "                objective_terms_assign.append(x[i, j])\n",
    "\n",
    "\n",
    "        solver.Minimize(solver.Sum(objective_terms_loss) - 2*th*solver.Sum(objective_terms_assign))\n",
    "\n",
    "        #solver.Minimize(solver.Sum(objective_terms))\n",
    "        # solver.Maximize(solver.Sum([x[i, j] for i in range(num_workers) for j in range(num_tasks)]))\n",
    "        #####################################################################\n",
    "\n",
    "        # The following code invokes the solver.\n",
    "        status = solver.Solve()\n",
    "\n",
    "        ######################################################################\n",
    "        # print the solution\n",
    "        count = 0\n",
    "        totCost = 0\n",
    "        x_values = np.zeros((num_sensors, num_measures), dtype= int)\n",
    "        recovered_solv = []\n",
    "        \n",
    "        recoverData = pd.DataFrame([], columns = ['Mean', 'Var','ID'])\n",
    "        \n",
    "        if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "            numOfSoln += 1\n",
    "            #print('Found a solution!!\\nTotal cost = ', solver.Objective().Value(), '\\n')\n",
    "            for i in range(num_sensors):\n",
    "                found = -1\n",
    "                for j in range(num_measures):\n",
    "                    x_values[i,j] = int(x[i,j].solution_value())\n",
    "\n",
    "                    # Test if x[i,j] is 1 (with tolerance for floating point arithmetic).\n",
    "                    if x[i, j].solution_value() > 0.5:\n",
    "                        found = j\n",
    "                        count+= 1\n",
    "    #                     print('Worker %d assigned to task %d.  Cost = %d' %\n",
    "    #                           (i, j, costs[i][j]))\n",
    "                        totCost += costs[i][j]\n",
    "\n",
    "                recovered_solv.append(found+1)\n",
    "            #print(count, totCost)\n",
    "            listOfind.append([recovered_solv])\n",
    "            listOfx.append(x_values)\n",
    "\n",
    "        \n",
    "        else:\n",
    "            print(\"Cant Solve!!!!!!\")\n",
    "            break\n",
    "\n",
    "        # Returning result\n",
    "        #optionsIndx = pd.DataFrame(np.unique(np.array(listOfind)[0]), axis = 0)\n",
    "        optionsIndx = pd.DataFrame(np.array(listOfind)[0])\n",
    "        #print(optionsIndx)\n",
    "        \n",
    "        for i, c in enumerate (optionsIndx.columns):\n",
    "\n",
    "            indexx = np.unique(optionsIndx[c])\n",
    "            indexx = indexx[indexx>0]\n",
    "            #print(i, c, indexx, indexx.shape)\n",
    "            if indexx.shape[0] == 0:\n",
    "                continue\n",
    "                \n",
    "            preSensor = predicted['ID'].iloc[c]\n",
    "            recoverData.loc[preSensor] = [0, 0, 0]\n",
    "            \n",
    "            #print(\"preSensor:\", preSensor)\n",
    "          \n",
    "#             try:\n",
    "#                 print(\"Rec Sensor:\")\n",
    "#                 print(indexx[0]-1)\n",
    "#                 print(received['ID'].iloc[indexx[0]-1])\n",
    "\n",
    "#                 #print(\"Rec Sensor:\", optionsIndx[c].iloc[0], received['ID'].iloc[optionsIndx[c].iloc[0]-1])\n",
    "#             except:\n",
    "#                 print(\"Shape:\", received['ID'].shape, \"But index:\", indexx[0]-1)\n",
    "#                 break\n",
    "            \n",
    "            recoverData['ID'].loc[preSensor] = received['ID'].iloc[indexx[0]-1]\n",
    "\n",
    "            #print('optionsIndx:', optionsIndx[c])\n",
    "            #print(f\"Sensor: {i+1}, Predicted: {predicted['MS'].iloc[i]}, indexx: {indexx}, data: {received['MS'].iloc[indexx-1].values}\\n\")\n",
    "            mean = np.mean(received['MS'].iloc[indexx-1].values)\n",
    "            var = np.square(np.std(received['MS'].iloc[indexx-1].values))\n",
    "            #print(recoverData)    \n",
    "            recoverData['Mean'].loc[preSensor] = mean\n",
    "            #print(recoverData) \n",
    "            recoverData['Var'].loc[preSensor] = var\n",
    "            #recoverData[['MS','Var']].loc[c] = [mean, var]\n",
    "        recoverData['Var'] = recoverData['Var'] + 1\n",
    "        recoverData = recoverData.dropna()\n",
    "        # msrList = np.array(list(recoverData.index))+1\n",
    "        # recoverData['ID'] = msrList\n",
    "        ###################\n",
    "        #print(\"recoverData: \\n\", recoverData, '\\n\\n')\n",
    "        dataCheck.append(recoverData)\n",
    "\n",
    "        pre_rec.append(dataCheck)\n",
    "        ##################\n",
    "    return recoverData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDecoy(Z_dec, consideredDecoyIDs):\n",
    "    \n",
    "    Z_active = Z_dec.copy()\n",
    "    Z_active[np.array(consideredDecoyIDs), 1] = 0\n",
    "    \n",
    "    # State Estimation and Bad Data Detection\n",
    "    States_decoy, Z_est_decoy, Z_mat_decoy, M_Noise_decoy, Noisy_index_decoy, Rank_decoy, Threshold_decoy = SE_BDD_COR(\n",
    "        H_org.copy(), Z_active.copy(), W_list, Threshold_min, Threshold_max, Correction, Verbose = \"False\")\n",
    "\n",
    "    Z_repeat = Z_dec.copy()\n",
    "    Z_repeat[consideredDecoyIDs,2] = Z_est_decoy[consideredDecoyIDs].copy()\n",
    "\n",
    "    for repeat in range(5):\n",
    "        # State Estimation and Bad Data Detection\n",
    "        # Running State Estimation\n",
    "        States_decoy, Z_est_decoy, Z_mat_decoy, M_Noise_decoy, Noisy_index_decoy, Rank_decoy, Threshold_decoy = SE_BDD_COR(\n",
    "            H_org.copy(), Z_repeat.copy(), W_list, Threshold_min, Threshold_max, Correction, Verbose = \"False\")\n",
    "        # Updating decoy Data\n",
    "\n",
    "        #print(np.linalg.norm(Z_est_decoy[consideredDecoyIDs]-Z_repeat[consideredDecoyIDs,2]))\n",
    "        Z_repeat[consideredDecoyIDs,2] = Z_est_decoy[consideredDecoyIDs]\n",
    "\n",
    "        #print(Z_mat_decoy[consideredDecoyIDs,1])\n",
    "        # Updating decoy Data\n",
    "        #print(np.linalg.norm(Z_repeat[consideredDecoyIDs,2] - Z_mat[consideredDecoyIDs,2]))\n",
    "    #print(Z_repeat[consideredDecoyIDs,2])\n",
    "    return Z_repeat[consideredDecoyIDs,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterData(Zrem, Zpre, th, fixedIDDs):\n",
    "    th = 5\n",
    "    #print(\"fixedIDDs\", fixedIDDs)\n",
    "    #print(Zrem.shape, Zpre.shape)\n",
    "    Zremm = Zrem.copy()\n",
    "    \n",
    "    for zr in Zremm.values:\n",
    "        if zr[0] in fixedIDDs or zr[0] == 0:\n",
    "            #print(\"Conitd..\", zr[0])\n",
    "            continue\n",
    "            \n",
    "        elif zr[1] == 1:\n",
    "            pred_value = Zpre['MS'].iloc[int(zr[0]-1)].copy()\n",
    "            #print(\"Actual and Predicted\", zr[2], pred_value)\n",
    "            if abs(zr[2] - pred_value) > abs(pred_value*th/100):             \n",
    "                zr[2] = pred_value.copy()\n",
    "                #print(\"Update:\", zr[2], pred_value)\n",
    "    return Zremm   \n",
    "\n",
    "\n",
    "th = 5\n",
    "def imputeData(Zrem, Zpre):\n",
    "    #print(Zrem.shape, Zpre.shape)\n",
    "    Zremm = Zrem.copy()\n",
    "    for zr in Zremm.values:\n",
    "        if zr[1] == -1 or  zr[1] == 0:\n",
    "            zr[1] = 1\n",
    "            pred_value = Zpre['MS'].iloc[int(zr[0]-1)].copy()\n",
    "            #print(zr[2], pred_value)\n",
    "            zr[2] = pred_value.copy()\n",
    "    return Zremm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defense Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defenseEval(Attack_Data, attackIndx, IDbank, attackerLevelList, verbose_ = True):\n",
    "    \n",
    "\n",
    "    AttackEval = []\n",
    "    detectionList = []\n",
    "    outliers_suspect_List_List= []\n",
    "    actually_attacked_list = []\n",
    "    \n",
    "#     successCount = 0\n",
    "#     totalAttackedSensors = 0\n",
    "#     endingIndx = 0\n",
    "    \n",
    "#     Sum_list_list = []\n",
    "#     deviNoiseList_list = []\n",
    "#     # Starting attacking one by one\n",
    "#     skipping = 0\n",
    "    \n",
    "\n",
    "\n",
    "    attackID = attackIndx #if attackIndx >= 0 else 0\n",
    "    #print(attackID, numOfAttack)\n",
    "\n",
    "#     if trial == True and attackID > 10:\n",
    "#         break\n",
    "#     if timed == True and skipping<attackID:\n",
    "#         break\n",
    "#     if attackID == numOfAttacks:\n",
    "#         skippingList.append(skipping)\n",
    "\n",
    "    #################################  \n",
    "\n",
    "    ###### Randomly Selecting Attacker Level ########\n",
    "    if attackertype == 3:\n",
    "        import random\n",
    "        attackertype_ = random.choice(range(3))\n",
    "    else: attackertype_ = attackertype\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    #&&&&&&&&&&&&&&&&&&&&&&&&&& Implementing the attack &&&&&&&&&&&&&&&&&&&&&&&&\n",
    "    #--------------------------------------------------------------------------#\n",
    "    attackerLevel = attackerLevelList[attackertype_]\n",
    "\n",
    "    selectedIDs = IDbank[attackertype_][0]\n",
    "    deceptiveIDs = IDbank[attackertype_][1]\n",
    "\n",
    "\n",
    "    #################################################\n",
    "    if verbose_: #pass \n",
    "        print(f\"\\nattackID: {attackID} \\t attackerLevel: {attackertype_}\")\n",
    "\n",
    "    #fixedIDs = Z_mat[1:][np.logical_not(np.array(server[0].deceptive).astype(bool)),0].astype(int)\n",
    "    #print('attackertype_:', attackertype_)\n",
    "    \n",
    "    if attackertype_ == -1:\n",
    "        selectedIDs = deceptiveIDs.copy()\n",
    "        Z_dec = Z_mat.copy() \n",
    "    \n",
    "    else:\n",
    "        # Z_dec is what attacker supposed to see\n",
    "        Z_dec = Z_mat.copy() \n",
    "        Z_dec [selectedIDs, 0] = deceptiveIDs.copy()\n",
    "        Z_dec = Z_dec [Z_dec[:,0].argsort(kind = 'mergesort')]\n",
    "    #####################################################\n",
    "    \n",
    "    if len(consideredDecoyIDs) > 0 and addDeciy == True:\n",
    "        Z_dec[consideredDecoyIDs, 2] = addDecoy(Z_dec, consideredDecoyIDs)\n",
    "\n",
    "    # running state estimation on deceived data ########\n",
    "    \n",
    "    # State Estimation and Bad Data Detection\n",
    "    States_dece, Z_est_dece, Z_mat_dece, M_Noise_dece, Noisy_index_dece, Rank_dece, Threshold_dece = SE_BDD_COR(\n",
    "        H_org.copy(), Z_dec.copy(), W_list, Threshold_min, Threshold_max, Correction, Verbose = \"False\")\n",
    "    #############################################\n",
    "    \n",
    "    \n",
    "    # Preparing the false data to be replaced \n",
    "    if attackID >= 0:\n",
    "        #print(\"Implementing Attack\")\n",
    "        attackGain = 2\n",
    "        startingIndx =  (attackID+1) * (numOfZ +1)\n",
    "        endingIndx = (attackID+2) * (numOfZ +1)\n",
    "        FData = Attack_Data[startingIndx : endingIndx,:].copy()\n",
    "    else: \n",
    "        #print(\"No Attack!\")\n",
    "        attackGain = 0\n",
    "        startingIndx =  (0) * (numOfZ +1)\n",
    "        endingIndx = (1) * (numOfZ +1)\n",
    "        FData = Attack_Data[startingIndx : endingIndx,:].copy()\n",
    "        \n",
    "    if abs(FData[:,2]).max() > 50:\n",
    "        FData[:,2] = FData[:,2]*50/abs(FData[:,2]).max()\n",
    "\n",
    "\n",
    "    injection = FData[:,2]* attackGain\n",
    "    \n",
    "    #print(injection, FData[:,2])\n",
    "    \n",
    "    FData[:,2] = injection + Z_dec[:,2]\n",
    "\n",
    "\n",
    "    # Attacker's intend to attack the following sensors\n",
    "    attackedIndx = np.where(injection != 0)[0]\n",
    "\n",
    "    # Replacing Z_dec by Z_attack which is received by the EMS \n",
    "    Z_att = Z_dec.copy()\n",
    "    \n",
    "    if attackCat == 'FDI':\n",
    "        Z_att[attackedIndx, 2] = FData[attackedIndx, 2].copy()\n",
    "    elif attackCat == 'DoS':\n",
    "        #Z_att[attackedIndx, 2] = FData[attackedIndx, 2].copy()\n",
    "        Z_att[attackedIndx, 1] = -1\n",
    "\n",
    "\n",
    "    # ------------->>>>>>>>>>>>>>> Filter with the reported sensors only ------------->>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "    if verbose_: print(\"Expected to attack: \", attackedIndx)        \n",
    "\n",
    "\n",
    "    ##--------------------------------------------------------------------------#\n",
    "    #&&&&&&&&&&&&&&&&&&&&&&&&&& Recovering from the attack &&&&&&&&&&&&&&&&&&&&\n",
    "    #--------------------------------------------------------------------------#\n",
    "    if runfilter == True or runImpute == True or recoveryType == 2:\n",
    "        # Zpre Data from LSTM\n",
    "        Zpre = predictLSTM (timeIndx)\n",
    "        #print(\"timeIndx: \", timeIndx)\n",
    "        #print(\" \\n\\Zpre:\\n\", Zpre)\n",
    "        ##############################\n",
    "    \n",
    "    # Received Data after Attack\n",
    "    received = pd.DataFrame(Z_att[Z_att[:, 1] == 1][1:,[0,2]], columns = ['ID', 'MS'])\n",
    "    received['ID'] = received['ID'].astype(int)\n",
    "    received.index = received['ID'] -1\n",
    "    #print(\"\\n\\nreceived:\\n\", received)\n",
    "\n",
    "    fixedIDDs = list(set(consideredFixedIDs).intersection(set(received['ID'].values)))\n",
    "    decoyIDDs = list(set(consideredDecoyIDs).intersection(set(received['ID'].values)))\n",
    "    #fixedIDDs = consideredFixedIDs\n",
    "    #print(consideredFixedIDs, received['ID'].values, fixedIDDs)\n",
    "\n",
    "        \n",
    "    if recoveryType == 1 or recoveryType == 2:\n",
    "        #print(\"Z_att\\n\\n\", Z_att)\n",
    "        # Derandomizing the received Z_att matrix -- > Z_rec\n",
    "        Z_rec = Z_att.copy()\n",
    "        Z_rec[deceptiveIDs, 0] = selectedIDs.copy()\n",
    "        Z_rec = Z_rec [Z_rec[:,0].argsort(kind = 'mergesort')]\n",
    "        #print(\"Z_rec:\\n\", Z_rec)\n",
    "        #******************************************************\n",
    "        Zpair = (Z_mat, Z_rec)\n",
    "        z_matrices.append(Zpair)\n",
    "        \n",
    "    if recoveryType == 2:\n",
    "        \n",
    "        Z_back = Z_att.copy()\n",
    "        Z_back[deceptiveIDs, 0] = selectedIDs.copy()\n",
    "        Z_back = Z_back [Z_back[:,0].argsort(kind = 'mergesort')]\n",
    "        \n",
    "        \n",
    "        #print(\">>>>>>>>>>>>> LSTM <<<<<<<<<<<<\")\n",
    "                \n",
    "        \n",
    "        recoverData = runMatch(numOfBuses, numOfLines, Zpre, received, fixedIDDs, decoyIDDs)\n",
    "        \n",
    "        ################################################\n",
    "        Z_rec = Z_att.copy()\n",
    "        \n",
    "        ##### find the index of recoered data #####\n",
    "        recoverdIndx = []\n",
    "        \n",
    "        for ids in recoverData['ID']:\n",
    "            recoverdIndx.append(np.where(Z_rec[:,0] == ids)[0][0])\n",
    "        \n",
    "        #print(recoverData['ID'], '\\n' ,recoverdIndx)\n",
    "        \n",
    "        Z_rec[recoverData.index, 2] = recoverData['Mean']\n",
    "        Z_rec[1:,1] = -1\n",
    "        Z_rec[0,1] = 1\n",
    "        Z_rec[recoverData.index, 1] = 1\n",
    "        ##########################################\n",
    "        Z_rec = Z_rec [Z_rec[:,0].argsort(kind = 'mergesort')]\n",
    "        \n",
    "        Zpair = (Z_back, Z_rec)\n",
    "        \n",
    "        #******************************************************\n",
    "        \n",
    "        #print(\"Difference: \", (Z_rec[[Z_rec[:,1] == 1,2]] - Z_back[[Z_rec[:,1] == 1,2]]).astype(int))\n",
    "\n",
    "    # Here only the randomization at the attacked layers is shown as the randomization as  \n",
    "    # rand at the rest of the layers will be recovered without any dataloss, thus skipped\n",
    "    #print(\"Z_rec\\n\", Z_rec)\n",
    "    \n",
    "    \n",
    "    #mapping the attacked locations\n",
    "    actually_attacked = np.sort((mapOrgID(attackedIndx.copy(), selectedIDs, deceptiveIDs)).astype(int))\n",
    "    targeted.append(attackedIndx)\n",
    "    \n",
    "    if verbose_: print(\"Actually attacked:\", actually_attacked)\n",
    "    attacked.append(actually_attacked)\n",
    "    if verbose_: print(\"Calling State Estimation for recovered data..:\")\n",
    "\n",
    "    # State Estimation and Bad Data Detection\n",
    "    States_check, Z_est_check, Z_mat_check, M_Noise_check, Noisy_index_check, Rank_check, Threshold_check = SE_BDD_COR(\n",
    "        H_org.copy(), Z_rec.copy(), W_list, Threshold_min, Threshold_max, Correction, Verbose = \"False\")\n",
    "    \n",
    "    savedState = (States_check, Z_est_check, Z_mat_check, M_Noise_check, Noisy_index_check, Rank_check, Threshold_check)\n",
    "    \n",
    "    runningfilter = False; runningImputer = False\n",
    "    \n",
    "    Z_rec_df = pd.DataFrame(Z_mat_check, columns = ['ID', 'Taken', 'MS'])\n",
    "    #########################  Adding LSTM Features ####################\n",
    "    if Rank_check == True:\n",
    "        if runfilter == True:\n",
    "            #print(\"Filtering Data\")\n",
    "            #print(\"Z_rec_df:\\n\", Z_rec_df)\n",
    "            Z_reco = filterData(Z_rec_df, Zpre, th, fixedIDDs)\n",
    "            Z_reco = Z_reco.values\n",
    "            runningfilter = True\n",
    "            #print(\"Z_reco:\\n\", Z_reco)\n",
    "    else:\n",
    "        if runImpute == True:\n",
    "            print(\"Imputing Data....\")\n",
    "            Z_reco = imputeData(Z_rec_df, Zpre)\n",
    "            Z_reco = Z_reco.values\n",
    "            runningImputer = True\n",
    "            \n",
    "    if runningfilter == True or runningImputer == True:\n",
    "        # State Estimation and Bad Data Detection\n",
    "        States_check, Z_est_check, Z_mat_check, M_Noise_check, Noisy_index_check, Rank_check, Threshold_check = SE_BDD_COR(\n",
    "            H_org.copy(), Z_reco.copy(), W_list, Threshold_min, Threshold_max, Correction, Verbose = \"False\")\n",
    "    \n",
    "        if runfilter == True and Rank_check == False:\n",
    "            print(\"LSTM prediction error!!\") if runfilter == True else print(\"Imputation Failed\")\n",
    "            (States_check, Z_est_check, Z_mat_check, M_Noise_check, Noisy_index_check, Rank_check, Threshold_check) = savedState\n",
    "            \n",
    "        if runImpute == True and Rank_check == False:\n",
    "            print(\"Imputation failed!!!!!!\")\n",
    "            \n",
    "            \n",
    "    #z_est_after_attack.append(Z_est_check.astype(int))\n",
    "    \n",
    "    #print(\"Threshold Threshold_check: \", Threshold_check)\n",
    "    M_Noise_check = Z_rec[:,2] - Z_est_check\n",
    "#         print(M_Noise_check[Noisy_index_check])\n",
    "#         print(\"\\n\\n\")\n",
    "    # eliminated attacked sensors\n",
    "    foundFDI_Idx =  sorted((set(Noisy_index_check)- set(Noisy_index_actu)) & set(actually_attacked))\n",
    "\n",
    "    # printing noisy indeces\n",
    "    if Noisy_index_check.size > 0 and verbose_ == True:\n",
    "        pass\n",
    "        #print(\"Noisy indeces before attack: \", Noisy_index_actu)\n",
    "        #print(\"Noisy indeces after attack: \", Noisy_index_check)\n",
    "\n",
    "    # system Unobservable\n",
    "    if Rank_check == False:\n",
    "        if verbose_: #pass\n",
    "            print(\"-----------  System Unobservable  --------------\")\n",
    "        # Pseudo Deviation \n",
    "        #Deviation = -10\n",
    "        Deviation = 0\n",
    "\n",
    "        AttackEval.append((attackID+1, \"unobservable\", Deviation))\n",
    "#             outliers_suspect_List = [[],[],[]]\n",
    "#             Sum_list = [[0],[0],[0]]\n",
    "#             deviNoiseList = [[0],[0],[0]]\n",
    "        AttackReturn = {}\n",
    "        #AttackReturn['StatesAttack'] =  States_check\n",
    "        AttackReturn['StatesAttack'] =  0\n",
    "        AttackReturn['StatesDeceived'] =  0\n",
    "        AttackReturn['Deviation']  = 0\n",
    "        AttackReturn['Check'] = 0\n",
    "        AttackReturn['Zpair'] = (0,0)\n",
    "    else:\n",
    "        # system is observable\n",
    "        # calculating the percent of deviation in the estiamted measurements\n",
    "        Deviation = np.linalg.norm(Z_est_check - Z_est_init) #/np.linalg.norm(Z_est_init)*100\n",
    "        #Deviation = np.linalg.norm(States_check - States_init)/np.linalg.norm(States_init)*100\n",
    "\n",
    "\n",
    "        ################ detecting/ checking for attack ####################\n",
    "    \n",
    "        ####################################################\n",
    "        attackertype_list.append(attackertype_)\n",
    "\n",
    "        ########################\n",
    "        totalAttackedSensors = np.sum(Z_rec[actually_attacked, 1])\n",
    "        ########################\n",
    "        successCount = len(set(Noisy_index_check) & set(actually_attacked))\n",
    "        #########################\n",
    "        if attackID > 0:\n",
    "            pass\n",
    "            #print(\"Noisy_index_check\", Noisy_index_check)\n",
    "            #print(\"actually_attacked\", actually_attacked)\n",
    "\n",
    "        # Detected as Bad Data\n",
    "        if len(foundFDI_Idx) > 0:\n",
    "            AttackEval = [attackID, \"detected\", Deviation]\n",
    "            \n",
    "            if verbose_: \n",
    "                print(\"!!!!!!!!!! Detected as Bad Data  !!!!!!!!!!!!\")\n",
    "                print(\"Detected Measurements: \", foundFDI_Idx)\n",
    "\n",
    "        # Attack was undetected \n",
    "        else:\n",
    "            if verbose_:print(\"$$$$$$$$$$$$$$  Successfull  $$$$$$$$$$$$$\")\n",
    "            AttackEval = [attackID, \"success\", Deviation]\n",
    "        \n",
    "        #print(\"skipping: \",skipping)\n",
    "        # skippingList.append(skipping)\n",
    "        # converting to matrix\n",
    "\n",
    "        \n",
    "        #successCount_avg = successCount / totalAttackedSensors * 100 if totalAttackedSensors > 0 else 0\n",
    "        AttackReturn = {}\n",
    "        #AttackReturn['StatesAttack'] =  States_check\n",
    "        AttackReturn['StatesAttack'] =  Z_est_check\n",
    "        AttackReturn['StatesDeceived'] =  Z_est_dece\n",
    "        AttackReturn['Deviation']  = AttackEval[2]\n",
    "        AttackReturn['Check'] = AttackEval[1]\n",
    "        AttackReturn['Zpair'] = Zpair\n",
    "\n",
    "    return AttackReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASP_list = []\n",
    "ASEU_list = []\n",
    "CSER_list = []\n",
    "EDR_list = []\n",
    "s_and_d_level = []\n",
    "s_and_d_sys = []\n",
    "\n",
    "outlier_list_level = []\n",
    "numOfBuses_list = [14, 57, 300]\n",
    "attackertypeList = [-1, 0, 1]\n",
    "attackerLevelList = ['Level 0', 'Level 1', 'Level 2']\n",
    "\n",
    "\n",
    "trial = True\n",
    "localize = False\n",
    "timed = False\n",
    "runfilter = False\n",
    "runImpute = False\n",
    "addDeciy = False\n",
    "decoyRepeat = False\n",
    "\n",
    "#*********** Modeling Attack's capability *************\n",
    "attacked_Bus = 5\n",
    "attacked_measurements = 5*attacked_Bus # default\n",
    "\n",
    "#attackerLevel = attackerLevelList[attackertype]\n",
    "#######################################################\n",
    "treeOn = 1\n",
    "randTypeList = ['random','tree']\n",
    "randType = randTypeList[treeOn]\n",
    "\n",
    "#######################################################\n",
    "\n",
    "# Simulation Repeat\n",
    "maxRepeat = 1\n",
    "######################################################\n",
    "\n",
    "#******************************************************\n",
    "# Noise threshold for SE-BDD algorithm\n",
    "Threshold_min = 1\n",
    "Threshold_max = 1\n",
    "#######################################################\n",
    "Correction = False\n",
    "\n",
    "########################################################\n",
    "#*********** Modeling Measurement Reading ************\n",
    "# Modeling Noise --> # mean and sd for Gaussian Noise\n",
    "noise_mu = 0\n",
    "noise_sigma_list = [0, 1, 2, 3]\n",
    "\n",
    "# Percent of sensors reported to the EMS\n",
    "percentOfreported_list = [50, 60, 70, 80, 90, 100]\n",
    "\n",
    "# Percent of sensors participated in deception\n",
    "percentOfDeception_list = [0, 25, 50, 75, 100]\n",
    "# percentOfFixed_list = [0, 25, 50, 75, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df  = pd.DataFrame([])\n",
    "#######################################################\n",
    "numOfBuses_list = [57]\n",
    "attackertypeList = [0,1,2]\n",
    "#percentOfDeception_list = [75]\n",
    "#percentOfFixed_list = [0, 25, 50, 75, 100]\n",
    "percentOfreported_list = [100]\n",
    "noise_sigma_list = [0]\n",
    "recoveryType = 1\n",
    "attackCat = 'FDI'\n",
    "attackFreq = 5\n",
    "##################################\n",
    "init = 500\n",
    "numdays = 0.01\n",
    "timestep = int(24*2*60*numdays)\n",
    "timestep = 250\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfAttacks = 250\n",
    "attackIndxxx  = np.arange(0, numOfAttacks)\n",
    "np.random.shuffle(attackIndxxx)\n",
    "# attackIndxxx = np.random.randint(100, size = timestep)\n",
    "#attackIndxxx[:] = -1\n",
    "\n",
    "# attackIndxxx = np.arange(1,timestep)\n",
    "attackIndxxx = attackIndxxx[0:timestep]\n",
    "print(attackIndxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_rec = []\n",
    "z_matrices = []\n",
    "attacked = []\n",
    "targeted = []\n",
    "EvalSum = {}\n",
    "\n",
    "EvalSum['random'] = []\n",
    "EvalSum['report'] = []\n",
    "EvalSum['fixed'] = []\n",
    "EvalSum['attType'] = []\n",
    "EvalSum['noOfbuses'] = []\n",
    "EvalSum['noise'] = []\n",
    "EvalSum['timeStep'] = []\n",
    "EvalSum['StatesInit'] = []\n",
    "EvalSum['StatesAttack'] = [] \n",
    "EvalSum['StatesDeceived'] = [] \n",
    "\n",
    "EvalSum['Deviation'] = [] \n",
    "EvalSum['Check'] = [] \n",
    "EvalSum['Zpair'] = []\n",
    "EvalSum['filter'] = []\n",
    "\n",
    "\n",
    "for q in range(1):\n",
    "    q = 0\n",
    "    if q == 0:\n",
    "        print(\"Seed-based Remap\")\n",
    "        recoveryType = 1\n",
    "        runfilter = False\n",
    "        runImpute = False\n",
    "        addDecoy = False\n",
    "    elif q == 1:\n",
    "        print(\"Forecast-based Remap\")\n",
    "        recoveryType = 2\n",
    "        runfilter = False\n",
    "        runImpute = True\n",
    "    else:\n",
    "        print(\"Hybrid Remap\")\n",
    "        recoveryType = 1\n",
    "        runfilter = True\n",
    "        runImpute = True\n",
    "\n",
    "    for numOfBuses in numOfBuses_list:\n",
    "        #start_time = time.time()\n",
    "        print(\"\\nnumOfBuses: \", numOfBuses)\n",
    "\n",
    "        for attackertype in attackertypeList:\n",
    "            print(\"\\nattackertype: \", attackertype)\n",
    "\n",
    "            for noise_sigma in noise_sigma_list:\n",
    "                print(\"\\nnoise_sigma:\", noise_sigma)\n",
    "                numOfStates = numOfBuses\n",
    "                ASEU_data = pd.DataFrame([])\n",
    "                file_name = f\"Bus Data\\\\IEEE_{numOfBuses}.xlsx\"\n",
    "\n",
    "                # Load data into Dataframes\n",
    "                bus_data_df = pd.read_excel (file_name, sheet_name = \"Bus\")\n",
    "                line_data_df = pd.read_excel (file_name, sheet_name = \"Branch\")\n",
    "\n",
    "                # number of lines and measurements\n",
    "                numOfLines = line_data_df.shape[0]\n",
    "                numOfZ = numOfBuses + numOfLines * 2\n",
    "                W_list = (numOfZ + 1)*[1]\n",
    "\n",
    "                # update the index from 1 to number of elements\n",
    "                bus_data_df.set_index(pd.Series(range(1, numOfBuses+1)), inplace = True)\n",
    "                line_data_df.set_index(pd.Series(range(1, numOfLines+1)), inplace = True)\n",
    "\n",
    "                # preprocess data and update line and bus numbers\n",
    "                #preprocess_data(bus_data_df, line_data_df)\n",
    "\n",
    "                # print(bus_data_df.head().T)\n",
    "                # print(line_data_df.head().T)\n",
    "                ###################################################################\n",
    "                # Loading Topology Data and Measurement Data\n",
    "                try:\n",
    "                    topo_mat = pd.read_excel(file_name, sheet_name = \"Topology Matrix\")\n",
    "                    line_data  = pd.read_excel(file_name, sheet_name = \"Line Data\")\n",
    "                    print(\"Topology Matrix Loaded!\")\n",
    "                except:\n",
    "                    print(\"Generating Topology Matrix...\")\n",
    "                    topo_mat, line_data = generate_topology_matrix(numOfBuses, numOfLines, line_data_df, file_name)\n",
    "\n",
    "                Topo = line_data.values.astype(int) #Another name\n",
    "                ###############################################################\n",
    "\n",
    "                # Loading Topology Data and Measurement Data\n",
    "                try:\n",
    "                    Z_msr_org = pd.read_excel(file_name, sheet_name = \"Measurement Data\")\n",
    "                    bus_data = pd.read_excel(file_name, sheet_name = \"Bus Data\")\n",
    "                    print(\"Measurement Data Loaded!\")\n",
    "                except:\n",
    "                    print(\"Generating Measurement Data...\")\n",
    "                    Z_msr_org, bus_data = generate_Z_msr_org(numOfBuses, numOfLines, bus_data_df, topo_mat, file_name)\n",
    "\n",
    "\n",
    "\n",
    "                # Adding IDs and Reported columns\n",
    "                Z_msr_org.insert(0, 'ID', list(Z_msr_org.index.values))\n",
    "                Z_msr_org.insert(1, 'Reported', [1]* (numOfZ+1))\n",
    "                #####################################################\n",
    "\n",
    "                #************  reading network topo data **************\n",
    "                fnetname = f'Bus Data//Net_Topo_{numOfBuses}.txt'\n",
    "                try: netdata = open(fnetname).readlines() \n",
    "                except: \n",
    "                    print(\"File Does not exist!\")\n",
    "                ######################################################\n",
    "\n",
    "                # Load Attack Data, otherwise generate attack data\n",
    "\n",
    "                file_Name_ = \"Attack_Space_\"+str(numOfBuses)+\"_\"+str(numOfLines)+\"_\"+str(attacked_Bus)+\".csv\"\n",
    "                try: \n",
    "                    Attack_Data = np.genfromtxt(\"Attack Data//\"+file_Name_, delimiter=',')\n",
    "                    print(\"Attack data loaded!\")\n",
    "                except:\n",
    "                    print(\"Attack Data is missing! Generating attack data!\")\n",
    "                    current_path = os.getcwd()\n",
    "                    Attack_Data = generate_attackdata(numOfBuses, numOfLines, line_data, attacked_Bus, current_path)\n",
    "\n",
    "                attackertype_list = []\n",
    "                numOfAttacks = int (Attack_Data.shape[0]/(numOfZ+1))\n",
    "                print(\"numOfAttacks: \", numOfAttacks)\n",
    "                meanZ= abs(Z_msr_org['Data']).mean()\n",
    "\n",
    "                ####################################################################\n",
    "                if localize == True:\n",
    "                    #Adding Noisy data\n",
    "                    Noise_Data = Attack_Data.copy()\n",
    "                    Noise_Data[:,2] = np.random.randint(-20,20, size = (Noise_Data.shape[0]))\n",
    "                    Noise_Data[Noise_Data[:,1] == 0, 2] = 0\n",
    "                    np.random.shuffle(Noise_Data[:,1:])\n",
    "\n",
    "                    # Updating attack data\n",
    "                    Attack_Data = np.concatenate((Attack_Data, Noise_Data), axis = 0)\n",
    "\n",
    "\n",
    "                #******************  sensor cluster mapping ************************************\n",
    "                sensorIDlist = list(range(1, numOfZ+1, 1))\n",
    "                clusterIDlist, clusterPopu = assignClusterID (sensorIDlist, Topo, numOfBuses, numOfLines)\n",
    "                ########################################################################################\n",
    "                #****************** Starting the loop ***********************\n",
    "\n",
    "                ###########   List for multiple randomization cases ################\n",
    "    #                 Attack_Summary_Mean_List = []\n",
    "    #                 Attack_Summary_Std_List = []\n",
    "    #                 HistData_List = []\n",
    "    #                 successCount_Mean =[]\n",
    "    #                 successCount_Std =[]\n",
    "\n",
    "    #                 DetectedCases_Mean_List = []\n",
    "    #                 DetectedCases_Std_List = []\n",
    "\n",
    "    #                 DetectionAccuracy_Mean_List = []\n",
    "    #                 DetectionAccuracy_Std_List = []\n",
    "\n",
    "    #                 successCount_Multi_list = []\n",
    "    #                 histData_Multi_list = []\n",
    "    #                 s_and_d = []\n",
    "    #                 outlier_list_dec = []\n",
    "\n",
    "                ####################################################################\n",
    "\n",
    "                for percentOfDeception in percentOfDeception_list:\n",
    "                    for percentOfreported in percentOfreported_list:\n",
    "\n",
    "                        print(\"percentOfDeception: \", percentOfDeception)\n",
    "                        print(\"percentOfreported: \", percentOfreported)\n",
    "                        #print(\"noise_sigma: \", noise_sigma)\n",
    "\n",
    "\n",
    "                        ###########  List for Multirun with same randomization #########\n",
    "                        Attack_Summary_Multi = []\n",
    "                        histData_Multi = []\n",
    "                        successCount_Multi =[]\n",
    "\n",
    "                        DetectedCases_Multi = []\n",
    "                        DetectionAccuracy_Multi = []\n",
    "                        ###############################################################\n",
    "\n",
    "                        # for repeat in range (maxRepeat):\n",
    "                        repeat = 1\n",
    "                        retry = 0\n",
    "                        while(repeat <= maxRepeat):\n",
    "                            #print(\"repeat: \",repeat)\n",
    "                            repeat += 1\n",
    "                            #------------------------------------------------------------------------------------------------\n",
    "                            #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&   Modeling Noise and Report and Deception &&&&&&&&&&&&&&&&&&\n",
    "                            #------------------------------------------------------------------------------------------------\n",
    "\n",
    "                            # Percent of observed sensors = 100 - reported \n",
    "                            percentOfobserved = 100 - percentOfreported  \n",
    "\n",
    "                            ##########################    Copying the original Data ###########################\n",
    "                            H_org = topo_mat.values.copy() \n",
    "                            Z_org = Z_msr_org.values.copy()\n",
    "                            ##################################################################################\n",
    "\n",
    "\n",
    "                            #############################    Modeling  noise   ###############################\n",
    "                            Noise = np.random.normal(noise_mu, noise_sigma, numOfZ)\n",
    "                            Z_org[1:,2] = np.multiply(Z_org[1:,2], Noise/100 + 1)\n",
    "                            ##################################################################################\n",
    "\n",
    "\n",
    "                            ############################  Modeling Data Reporting  ###########################\n",
    "                            randomIDs = np.arange(1,numOfZ)\n",
    "                            np.random.shuffle(randomIDs)\n",
    "                            overservedIDs = randomIDs[0: int (percentOfobserved*numOfZ/100)]\n",
    "                            Z_org[overservedIDs, 1] = 0 # updating Z_org \n",
    "\n",
    "                            ### ----------->>  Check observability ---->>>\n",
    "                            #print(Z_org)\n",
    "                            Z_mat = Z_org.copy()   \n",
    "                            ###################################################################################\n",
    "\n",
    "\n",
    "                            ##########################   Modeling Deception   #################################\n",
    "                            Deception_flag = []\n",
    "                            for index in range(Z_mat[1:].shape[0]):\n",
    "                                Deception_flag.append([])\n",
    "                            ## Flipping coin each time for each sensor to decide on deception ##########\n",
    "                            for Z in Z_mat[1:,:]:\n",
    "                                toss = np.random.binomial(size = 1, n = 1, p = percentOfDeception/100)[0]\n",
    "                                Deception_flag[Z[0].astype(int) - 1].append(0 if Z[1].astype(int) == 0 else toss)\n",
    "                            #print(Deception_flag)\n",
    "                            ####################################################################################\n",
    "\n",
    "\n",
    "                            #------------------------------------------------------------------------------------------------\n",
    "                            #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& SE and BDD &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "                            #------------------------------------------------------------------------------------------------\n",
    "\n",
    "                            # State Estimation and Bad Data Detection\n",
    "                            States_init, Z_est_init, Z_mat_init, M_Noise_actu, Noisy_index_actu, fullRank, Threshold = SE_BDD_COR(\n",
    "                                 H_org.copy(), Z_org.copy(), W_list, Threshold_min, Threshold_max, Correction, Verbose = \"False\")\n",
    "\n",
    "\n",
    "                            if fullRank == False:\n",
    "                                if retry < maxRepeat:\n",
    "                                    print(\"The systen is not observable--> Retrying\")\n",
    "                                    repeat -= 1\n",
    "                                    retry += 1\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    print(\"The number of reported measurements are too low!\")\n",
    "                                    break\n",
    "\n",
    "                    #         print(\"SE threshold for original data : \", Threshold)\n",
    "                    #         print(\"Noisy Index in the original data: \", Noisy_index_actu)\n",
    "                    #         print(\"fullRank: \", fullRank)\n",
    "                            ##################################################################################################\n",
    "                            #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "\n",
    "                            #------------------------------------------------------------------------------------------------\n",
    "                            #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&  Constructing the Network Topology &&&&&&&&&&&&&&&&&&&&&&&&&&& \n",
    "                            #-------------------------------------------------------------------------------------------------\n",
    "                            #start_time = time.time() \n",
    "                            ######################### Constrcuting Clusters #################################################\n",
    "                            lineID = 0\n",
    "                            clusterList =[]\n",
    "                            clusterSensorData_List = []\n",
    "                            shuffleFlagcluster = []\n",
    "\n",
    "                            while(True):\n",
    "                                # reading the line\n",
    "                                line = netdata[lineID]\n",
    "                                lineID = lineID + 1\n",
    "\n",
    "                                #checking for # or spaces\n",
    "                                if line[0] == '#' or line[0] == '\\n':\n",
    "                                    continue\n",
    "\n",
    "                                # found values\n",
    "                                else: \n",
    "                                    #print(line)\n",
    "                                    numberOfcluster = int (line.strip())\n",
    "                                    #print(\"numberOfcluster:\", numberOfcluster)\n",
    "                                    #adding cluster blank list\n",
    "                                    for index in range (numberOfcluster):\n",
    "                                        clusterList.append([])\n",
    "                                        clusterSensorData_List.append([])\n",
    "                                        shuffleFlagcluster.append([])\n",
    "                                    for s, c in zip(sensorIDlist, clusterIDlist):\n",
    "                                        clusterList[c-1].append(s)\n",
    "                                    #print(\"clusterList: \", clusterList)\n",
    "                                    break\n",
    "\n",
    "                            ######################### Constrcuting Hubs ########################################\n",
    "                            hubList = []\n",
    "                            hubSensorData_List = []\n",
    "                            shuffleFlagHub = []\n",
    "\n",
    "                            # calling function to read hub data\n",
    "                            hubList, hubSensorData_List, shuffleFlagHub, numOfhub, lineID = readX(\n",
    "                                hubList, hubSensorData_List, shuffleFlagHub, netdata, lineID)\n",
    "                            #print(hubList)\n",
    "\n",
    "                            ######################## Constrcuting Servers   ###################################\n",
    "                            serverList = []\n",
    "                            serverSensorData_List =[]\n",
    "                            shuffleFlagServer = []\n",
    "\n",
    "                            # calling function to read server data\n",
    "                            serverList, serverSensorData_List, shuffleFlagServer, numOfserver, lineID = readX(\n",
    "                                serverList, serverSensorData_List, shuffleFlagServer, netdata, lineID)\n",
    "                            #################################################################################\n",
    "                            #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "\n",
    "\n",
    "                            #--------------------------------------------------------------------------------------------\n",
    "                            #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&  Setting up Nodes with measurement data &&&&&&&&&&&&&&&&&&&&&\n",
    "                            #---------------------------------------------------------------------------------------------\n",
    "\n",
    "                            ##################### initializing sensor nodes ######################################\n",
    "                            sensor = []\n",
    "                            for Z in Z_mat[1:]:\n",
    "                                sensor.append(Node())\n",
    "                                sensorID = Z[0].astype(int) - 1\n",
    "                                sensor[sensorID].nodeType = 'Sensor'\n",
    "                                sensor[sensorID].nodeID = sensorID + 1\n",
    "                                sensor[sensorID].leaf = True\n",
    "                                sensor[sensorID].totSensor = 1\n",
    "                                sensor[sensorID].decSensor = Deception_flag[sensorID][0]\n",
    "                                sensor[sensorID].remSensor = Deception_flag[sensorID][0]\n",
    "                                sensor[sensorID].ids.append(sensorID + 1)\n",
    "                                sensor[sensorID].reported.append(Z[1].astype(int))\n",
    "                                sensor[sensorID].deceptive.append(Deception_flag[sensorID][0])\n",
    "                                sensor[sensorID].values.append(Z[2])\n",
    "\n",
    "                            ##################### initializing cluster nodes ######################################\n",
    "                            cluster = []\n",
    "                            for (index, eachcluster) in enumerate(clusterList):\n",
    "                                #print(eachcluster)\n",
    "                                cluster.append(Node())\n",
    "\n",
    "                                cluster[index].nodeType = 'Cluster'\n",
    "                                cluster[index].nodeID = index + 1\n",
    "                                for sensorID in eachcluster:\n",
    "                                    cluster[index].addChild(sensor[sensorID-1])\n",
    "\n",
    "                            ##################### initializing hub nodes ######################################\n",
    "                            hub = []\n",
    "                            for (index, eachhub) in enumerate(hubList):\n",
    "                                #print(eachhub, )\n",
    "                                hub.append(Node())\n",
    "                                hub[index].nodeType = 'Hub'\n",
    "                                hub[index].nodeID = index + 1\n",
    "                                for clusterID in eachhub:\n",
    "                                    hub[index].addChild(cluster[clusterID-1])\n",
    "                                #hub[index].printNode()\n",
    "\n",
    "                            ##################### initializing server nodes ######################################\n",
    "                            server = []\n",
    "                            for (index, eachserver) in enumerate(serverList):\n",
    "\n",
    "                                #print(eachserver)\n",
    "                                server.append(Node())\n",
    "                                server[index].nodeType = 'Server'\n",
    "                                server[index].nodeID = index + 1\n",
    "                                for hubID in eachserver:\n",
    "                                    server[index].addChild(hub[hubID-1])\n",
    "                                #server[index].printNode()\n",
    "                            #######################################################################################\n",
    "\n",
    "\n",
    "                            #------------------------------------------------------------------------------------------------\n",
    "                            #&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&  Randmization at each level &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "                            #------------------------------------------------------------------------------------------------\n",
    "\n",
    "                            # collection of all randomized IDs stored at EMS \n",
    "                            IDbank = []\n",
    "\n",
    "                            # List of org and dec IDs at different level of communication channel\n",
    "                            orgIDsCluster = []\n",
    "                            decIDsCluster = []\n",
    "                            orgIDsHub = []\n",
    "                            decIDsHub = []\n",
    "                            orgIDsServer = []\n",
    "                            decIDsServer = [] \n",
    "\n",
    "                            # Randomizing at cluster\n",
    "                            for clusterID in range(numberOfcluster):\n",
    "                                orgclusterID, decclusterID = randomizeID(cluster[clusterID], randType)\n",
    "                                orgIDsCluster += orgclusterID\n",
    "                                decIDsCluster += decclusterID                \n",
    "\n",
    "                            # Randomizing at hub\n",
    "                            for hubID in range(numOfhub):\n",
    "                                orghubID, dechubID = randomizeID(hub[hubID], randType)\n",
    "                                orgIDsHub += orghubID\n",
    "                                decIDsHub += dechubID\n",
    "\n",
    "                            # Randomizing at server\n",
    "                            for serverID in range(numOfserver):\n",
    "                                orgserverID, decserverID = randomizeID(server[serverID], randType)\n",
    "                                orgIDsServer += orgserverID\n",
    "                                decIDsServer += decserverID\n",
    "\n",
    "                            # Merging all the orgIDs and decIDs at diiferent level\n",
    "                            ID_Stack = [(orgIDsCluster, decIDsCluster),(orgIDsHub, decIDsHub),(orgIDsServer, decIDsServer)]\n",
    "                            IDbank = func_dec_view(ID_Stack)\n",
    "\n",
    "                            # Fixed IDs Loop\n",
    "                            x =pd.DataFrame([])\n",
    "                            x['ID'] = server[0].ids\n",
    "                            x['DC'] = server[0].deceptive\n",
    "                            x['RP'] = server[0].reported\n",
    "                            filter1 = np.array(x['DC'] == 0)\n",
    "                            filter2 = np.array(x['RP'] == 1)\n",
    "                            filterr = np.logical_and(filter1, filter2)\n",
    "                            fixedIDs = list(x['ID'].loc[filterr])\n",
    "\n",
    "                            # Fixed IDs Loop\n",
    "\n",
    "                            \n",
    "                            \n",
    "                            initrange = 100-percentOfDeception if decoyRepeat == False else 0\n",
    "                                                      \n",
    "                            #initrange = 0\n",
    "                            \n",
    "                            for percentOffixed in range(initrange, 100-percentOfDeception+1, 5):\n",
    "                                                \n",
    "                                print(\"percentOffixed: \", percentOffixed)\n",
    "                                totalFixedPoints = int(numOfZ*percentOffixed/100)\n",
    "\n",
    "                                consideredFixedIDs = fixedIDs[0:totalFixedPoints]\n",
    "                                consideredDecoyIDs = fixedIDs[totalFixedPoints:]\n",
    "                                #print('consideredFixedIDs:',consideredFixedIDs)\n",
    "                                #print('consideredDecoyIDs:',consideredDecoyIDs)\n",
    "                            \n",
    "#                             #initrange = 100-percentOfDeception if recoveryType == 1 else 0\n",
    "#                             initrange = 100-percentOfDeception\n",
    "#                             for percentOffixed in range(initrange, 100-percentOfDeception+1, 25):\n",
    "#                                 print(\"percentOffixed: \", percentOffixed)\n",
    "#                                 totalFixedPoints = int(numOfZ*percentOffixed/100)\n",
    "\n",
    "#                                 consideredFixedIDs = fixedIDs[0:totalFixedPoints]\n",
    "#                                 #print(\"FixedIDS: \",fixedIDs, consideredFixedIDs)\n",
    "\n",
    "                                for timeIndx in range(init, init+timestep):\n",
    "\n",
    "                                    if timeIndx%attackFreq == 1:\n",
    "                                        attackIndx = attackIndxxx[timeIndx-init]\n",
    "                                    else: \n",
    "                                        attackIndx = -1\n",
    "\n",
    "                                    try:\n",
    "                                        senMsr = Y_test[timeIndx]\n",
    "                                    except:\n",
    "                                        senMsr = Z_est_init[1:].copy()\n",
    "                                    senMsr = np.concatenate((np.array([0]), senMsr), axis =0 )\n",
    "                                    senMsr[-numOfBuses:] = senMsr[-numOfBuses:]*(-1)                                   \n",
    "                                    Z_org[:,2] = senMsr\n",
    "                                    ##################################################################################\n",
    "\n",
    "\n",
    "                                    #############################    Modeling  noise   ###############################\n",
    "                                    Noise = np.random.normal(noise_mu, noise_sigma, numOfZ)\n",
    "                                    Z_org[1:,2] = np.multiply(Z_org[1:,2], Noise/100 + 1)\n",
    "                                    ##################################################################################\n",
    "                                    #print(Z_org)\n",
    "                                    Z_mat = Z_org.copy()   \n",
    "\n",
    "                                    ###################################################################################\n",
    "                                    # State Estimation and Bad Data Detection\n",
    "                                    States_init, Z_est_init, Z_mat_init, M_Noise_actu, Noisy_index_actu, fullRank, Threshold = SE_BDD_COR(\n",
    "                                         H_org.copy(), Z_org.copy(), W_list, Threshold_min, Threshold_max, Correction, Verbose = \"False\")\n",
    "\n",
    "\n",
    "                                    #print(\"\\n\\nZ_msr_org:\\n\", Z_msr_org)\n",
    "\n",
    "\n",
    "                                    #IDbank = ID_Stack.copy()\n",
    "                                    #------------------------------------------------------------------------------------------------\n",
    "                                    #&&&&&&&&&&&&&&&&&&&&&&&&&& Evaluation on State Estimation Attack &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "                                    #------------------------------------------------------------------------------------------------\n",
    "                                    #time1 = time.time() - start_time\n",
    "                                    #start_time = time.time() \n",
    "                                    ################################  Launching  Attacks ################################\n",
    "                                    attackEval = defenseEval(Attack_Data, attackIndx, IDbank, attackerLevelList, verbose_ = False)\n",
    "\n",
    "            #                         AttackEval, Attack_Summary, histDatadeviation, successCount_avg, detectionList, \\\n",
    "            #                         s, d, outlier_sus, outlier_org = defenseEval(\n",
    "            #                             attacked_Bus, Attack_Data, IDbank, attackerLevelList, attackIndx, verbose_ = False)\n",
    "\n",
    "                                    #time2 = time.time() - start_time\n",
    "                                    #time_df [numOfBuses] = [time1, time2]\n",
    "                                    #print(attackEval)\n",
    "\n",
    "                                    EvalSum['random'].append(percentOfDeception)\n",
    "                                    EvalSum['report'].append(percentOfreported)\n",
    "                                    EvalSum['fixed'].append(percentOffixed)\n",
    "                                    EvalSum['attType'].append(attackertype)\n",
    "                                    EvalSum['noOfbuses'].append(numOfBuses)\n",
    "                                    EvalSum['noise'].append(noise_sigma)\n",
    "                                    EvalSum['timeStep'].append(timeIndx)\n",
    "                                    #EvalSum['StatesInit'].append(States_init)\n",
    "                                    EvalSum['StatesInit'].append(Z_est_init)\n",
    "                                    EvalSum['StatesDeceived'].append(attackEval['StatesDeceived'])\n",
    "                                    EvalSum['StatesAttack'].append(attackEval['StatesAttack']) \n",
    "                                    EvalSum['Deviation'].append(attackEval['Deviation'])\n",
    "                                    EvalSum['Check'].append(attackEval['Check'])\n",
    "                                    EvalSum['Zpair'].append(attackEval['Zpair']) \n",
    "                                    EvalSum['filter'].append(q)\n",
    "                                \n",
    "EvalSum = pd.DataFrame.from_dict(EvalSum)\n",
    "fixedList = list(np.unique(EvalSum['fixed']))\n",
    "randList = list(np.unique(EvalSum['random']))\n",
    "\n",
    "dev = np.array(EvalSum['StatesInit'] - EvalSum['StatesDeceived'])\n",
    "dev = np.linalg.norm(np.array([x for x in dev]), axis = 1)\n",
    "EvalSum['EstDec'] = dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvalSum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
